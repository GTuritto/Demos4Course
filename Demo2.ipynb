{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHYIb0+Wh9yncDpKrBT7Aw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GTuritto/Demos4Course/blob/main/Demo2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Projecto Documentador de Software"
      ],
      "metadata": {
        "id": "bOaPnqVsLT78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instalamos los paquetes requeridos**\n"
      ],
      "metadata": {
        "id": "bAI77r2UKutW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyautogen dask[dataframe] mistralai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OlIHEZXgsRJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importamos las dependencias necesarias**"
      ],
      "metadata": {
        "id": "oSGzLabfLKpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "from google.colab import userdata\n",
        "\n",
        "import autogen\n",
        "import os\n",
        "import json\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "QzYWpILeLeWI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuramos la conexion al API del LLM"
      ],
      "metadata": {
        "id": "QpY-Kwi9Lk43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API Configuracion para OpenAI\n",
        "# apiConfig = [{\n",
        "#        \"model\": \"gpt-4o-mini\",\n",
        "#        \"max_tokens\": 500,\n",
        "#        \"api_key\": userdata.get('OPENAI_API_KEY')\n",
        "#    }]\n",
        "\n",
        "\n",
        "# API Configuracion para Mistral -- Preferimos usar esta para las pruebas ya que no hay que pagar y es tan buena como la de OpenAI\n",
        "api_config = [{\n",
        "        \"model\": \"mistral-large-latest\",\n",
        "        \"max_tokens\": 2000,\n",
        "        \"api_key\": userdata.get('MISTRAL_API_KEY'),\n",
        "        \"api_type\": \"mistral\"\n",
        "    }]\n",
        "\n",
        "# Configuración para el LLM, incluyendo lógica de reintentos y semilla de caché para consistencia\n",
        "llm_config = {\n",
        "    \"config_list\": api_config,\n",
        "    \"cache_seed\": 42,  # Semilla de caché para un comportamiento consistente\n",
        "    \"retry_on_rate_limit\": True,  # Reintentar si se alcanza el límite de la API\n",
        "    \"retry_on_timeout\": True,     # Reintentar si hay un tiempo de espera\n",
        "    \"max_retries\": 5,             # Número máximo de reintentos\n",
        "    \"retry_delay\": 0.3,           # Retraso más corto para reintentos más rápidos\n",
        "}"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WjCldcvnLrJo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creemos los Agentes\n",
        "\n",
        "Aqui controlaremos la creatividad de los agentes, ya que queremos que el Product Manager se un poco mas creativo que el resto"
      ],
      "metadata": {
        "id": "_xk-nxhFM4ch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User Proxy\n",
        "\n",
        "El agente que servira del proxy para la iteracion con el usuario"
      ],
      "metadata": {
        "id": "fx9KtMFMNOl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User Proxy Agent\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"User_proxy\",\n",
        "    system_message=\"A human admin.\",\n",
        "    code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"groupchat\"},\n",
        "    human_input_mode=\"TERMINATE\"\n",
        ")"
      ],
      "metadata": {
        "id": "P9Le_n-mNIso"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Niveles de Creatividad (temperature)"
      ],
      "metadata": {
        "id": "9VBUgSaSD3FQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom temperature for each agent\n",
        "\n",
        "llm_config_high = llm_config.copy()\n",
        "llm_config_high[\"temperature\"] = 0.9 # More creative than usual\n",
        "\n",
        "llm_config_low = llm_config.copy()\n",
        "llm_config_low[\"temperature\"] = 0.5 # Less creative, more structured\n",
        "\n",
        "llm_config_normal = llm_config.copy()\n",
        "llm_config_normal[\"temperature\"] = 0.7 # Normal level of creativity"
      ],
      "metadata": {
        "id": "ER0ga8--C7vH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agente Product Manager\n",
        "\n",
        "Agente que actua como un Product Manager"
      ],
      "metadata": {
        "id": "GeqlOwaHNdbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Product Manager Agent\n",
        "pm = autogen.AssistantAgent(\n",
        "    name=\"Product_Manager\",\n",
        "    system_message=\"You are an amazing Product Manager, creative in software product ideas, with knowledge in multiples verticals\",\n",
        "    llm_config=llm_config_high,\n",
        ")\n"
      ],
      "metadata": {
        "id": "1LOc1o6_N1if"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agente Business Analyst\n",
        "\n",
        "Agente que actua como un Business Analyst"
      ],
      "metadata": {
        "id": "jXNWBG-XPUDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Business Analyst Agent\n",
        "ba = autogen.AssistantAgent(\n",
        "    name=\"Business_Analyst\",\n",
        "    system_message=\"Act as an Expert in business analysis and requirements gathering.\",\n",
        "    llm_config=llm_config_low,\n",
        ")"
      ],
      "metadata": {
        "id": "4yFPOcfRPajF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agente Architect\n",
        "\n",
        "Agente que actua como un Arquitecto de Software"
      ],
      "metadata": {
        "id": "3m8O9GiSQKFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Architect Agent\n",
        "architect = autogen.AssistantAgent(\n",
        "    name=\"Architect\",\n",
        "    system_message=\"You are a Software Architect, with expereience in creating escalable and solid architectures, you have knowledge of Microservices and distributed monolith, as well architecture for FrontEnd in Web and Mobile. You are responsible for defining the architecture and design decisions.\",\n",
        "    llm_config=llm_config_normal,\n",
        ")"
      ],
      "metadata": {
        "id": "QnTk5q0AQLPB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agente Coder\n",
        "\n",
        "Agente que actua como un Ingeniero de Software"
      ],
      "metadata": {
        "id": "9xvmaApRQLjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Coder Assistant Agent\n",
        "coder = autogen.AssistantAgent(\n",
        "    name=\"Coder\",\n",
        "    system_message=\"Act as a Staff Software Engineer.\",\n",
        "    llm_config=llm_config_normal,\n",
        ")"
      ],
      "metadata": {
        "id": "hNtXBi6jQMRt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agente Analista de QA\n",
        "\n",
        "Agente que actua como un experto en **QA**"
      ],
      "metadata": {
        "id": "6hFpPatSSWkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# QA Agent\n",
        "qa = autogen.AssistantAgent(\n",
        "    name=\"QA\",\n",
        "    system_message=\"Expert in testing strategies, risk analysis and creating BDD specifications. You are responsible to create the Testing Plan, y Gerhkin Specifications\",\n",
        "    llm_config=llm_config_low,\n",
        ")"
      ],
      "metadata": {
        "id": "RQo0v82ZQOF5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agente generador de Documentacion\n",
        "\n",
        "Este agente esta encargdo de generar el Documento final, combinando los documentos de cada uno de los integrantes, coordinacion de la generacion de documentos y revisa y genera recomendacion para mejorar el documento"
      ],
      "metadata": {
        "id": "ttM_YcW1QNtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Documentation Agent\n",
        "\n",
        "class DocumentationAgent(autogen.AssistantAgent):\n",
        "    def __init__(self, name, llm_config):\n",
        "        super().__init__(name=name, llm_config=llm_config)\n",
        "        self.final_document = {}\n",
        "\n",
        "    def contribute(self, agent_name, section_title, content):\n",
        "        # Each agent contributes to the final document\n",
        "        self.final_document[agent_name] = {\n",
        "            \"section_title\": section_title,\n",
        "            \"content\": content\n",
        "        }\n",
        "\n",
        "    def generate_final_document(self):\n",
        "        # Create documentation folder if it doesn't exist\n",
        "        if not os.path.exists(\"documentation\"):\n",
        "            os.makedirs(\"documentation\")\n",
        "\n",
        "        # Combine all contributions into a final document\n",
        "        final_content = \"# Final Documentation\\n\\n\"\n",
        "        for agent_name, section in self.final_document.items():\n",
        "            final_content += f\"## {section['section_title']}\\n\\n{section['content']}\\n\\n\"\n",
        "\n",
        "        # Write the Markdown file\n",
        "        markdown_path = \"documentation/final_document.md\"\n",
        "        with open(markdown_path, \"w\") as md_file:\n",
        "            md_file.write(final_content)\n",
        "\n",
        "        print(f\"Final document created in 'documentation' folder:\\n- {markdown_path}\")\n",
        "        return markdown_path\n",
        "\n",
        "    def self_reflect_and_improve(self, agent_name):\n",
        "        # Each agent self-reflects on their contribution and suggests improvements\n",
        "        reflection = f\"{agent_name} self-reflects and suggests improvements on their section.\"\n",
        "        print(f\"{agent_name}: {reflection}\\n\")\n",
        "        self.final_document[agent_name][\"content\"] += f\"\\n\\n**Self-Reflection and Improvements:**\\n\\n{reflection}\"\n",
        "\n",
        "    def peer_review(self, agent_name, reviewer_name):\n",
        "        # Each agent reviews the contribution of another agent and suggests improvements\n",
        "        review = f\"{reviewer_name} reviews {agent_name}'s section and suggests improvements.\"\n",
        "        print(f\"{reviewer_name}: {review}\\n\")\n",
        "        self.final_document[agent_name][\"content\"] += f\"\\n\\n**Peer Review by {reviewer_name}:**\\n\\n{review}\"\n",
        "\n",
        "# Instantiate the Documentation Agent\n",
        "doc_agent = DocumentationAgent(\n",
        "    name=\"Documentation_Agent\",\n",
        "    llm_config=llm_config_normal\n",
        ")\n"
      ],
      "metadata": {
        "id": "qb4qWSu7TM4X"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creacion del Chat de grupo de Agentes"
      ],
      "metadata": {
        "id": "I5NhgqgMJhXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GroupChat Setup with all agents\n",
        "groupchat = autogen.GroupChat(agents=[user_proxy, pm, ba, architect, coder, qa, doc_agent], messages=[], max_round=12)\n",
        "\n",
        "# GroupChat Manager to orchestrate the chat\n",
        "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n"
      ],
      "metadata": {
        "id": "N9n9xx4HJN3n"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fases de Colaboración\n",
        "\n",
        "En esta seccion definiremos la coordinacion entre Agentes.\n",
        "\n",
        "Hemos dividido el proceso en tres fases de colaboración, la primera fase es una colaboración entre los agentes Product Manager y el Business Analyst, ellos generara un Documento que sera usado en la siguiente fase.\n",
        "La segunda fase es una colaboración entre los agentes Coder, Architect y QA, en esta fase colaboraran y ampliaran añadiendo su conocimiento sobre el documento creado por los agenes Product Manager y Business Analyst.\n",
        "La ultima y tercera fase, es es Agente de Documentación recopilar todo en un unico documento revisar y hacer sugerencias a cada uno de los agentes anteriores para revisar el contenido.\n",
        "\n",
        "Todo termina cuando no hay mas sugerencias que hacer."
      ],
      "metadata": {
        "id": "Hy7Ze52z7cmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fase 1"
      ],
      "metadata": {
        "id": "irQGpeVM92OR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to simulate the collaboration in Phase 1\n",
        "def phase_1_collaboration():\n",
        "    print(\"Phase 1: Product Manager and Business Analyst Collaboration\\n\")\n",
        "\n",
        "    # Product Manager and Business Analyst collaborate\n",
        "    for agent in [pm, ba]:\n",
        "        response = agent.generate_reply(groupchat.messages)\n",
        "        content = response.get('content', '') if isinstance(response, dict) else response\n",
        "\n",
        "        if agent.name == \"Product_Manager\":\n",
        "            doc_agent.contribute(agent.name, \"Product Requirements Document (PRD)\", content)\n",
        "        elif agent.name == \"Business_Analyst\":\n",
        "            doc_agent.contribute(agent.name, \"Business Requirements and Use Cases\", content)\n",
        "\n",
        "        print(f\"{agent.name} contributed to the document in Phase 1.\\n\")\n"
      ],
      "metadata": {
        "id": "x6mrezxD-GLQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fase 2"
      ],
      "metadata": {
        "id": "zlV2YBunVWAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to simulate the collaboration in Phase 2\n",
        "def phase_2_collaboration():\n",
        "    print(\"Phase 2: Coder, Architect, and QA Collaboration\\n\")\n",
        "\n",
        "    # Coder and Architect work together, and QA works in parallel\n",
        "    for agent in [coder, architect, qa]:\n",
        "        response = agent.generate_reply(groupchat.messages)\n",
        "        content = response.get('content', '') if isinstance(response, dict) else response\n",
        "\n",
        "        if agent.name == \"Coder\":\n",
        "            doc_agent.contribute(agent.name, \"Implementation Plan\", content)\n",
        "        elif agent.name == \"Architect\":\n",
        "            doc_agent.contribute(agent.name, \"Architectural Decisions\", content)\n",
        "        elif agent.name == \"QA\":\n",
        "            doc_agent.contribute(agent.name, \"Testing Plan and BDD Specifications\", content)\n",
        "\n",
        "        print(f\"{agent.name} contributed to the document in Phase 2.\\n\")\n"
      ],
      "metadata": {
        "id": "rcYORGYa-HEa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fase3"
      ],
      "metadata": {
        "id": "8tvEMb5v-BZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to simulate the final revision in Phase 3\n",
        "def phase_3_revision():\n",
        "    print(\"Phase 3: Final Revision and Improvement\\n\")\n",
        "\n",
        "    # Self-reflection and peer review\n",
        "    for agent in groupchat.agents:\n",
        "        if agent.name != \"User_proxy\" and agent.name != \"Documentation_Agent\":\n",
        "            doc_agent.self_reflect_and_improve(agent.name)\n",
        "\n",
        "    for agent in groupchat.agents:\n",
        "        if agent.name != \"User_proxy\" and agent.name != \"Documentation_Agent\":\n",
        "            for reviewer in groupchat.agents:\n",
        "                if reviewer.name != \"User_proxy\" and reviewer.name != agent.name and reviewer.name != \"Documentation_Agent\":\n",
        "                    doc_agent.peer_review(agent.name, reviewer.name)\n"
      ],
      "metadata": {
        "id": "l7W6Etyb-Hee"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activacion\n",
        "\n",
        "Aqui definimos que deben de documentar todos estos agentes y empezamos cada una de las fases"
      ],
      "metadata": {
        "id": "ZyP-HJXU7Y6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to start the conversation and generate the final document\n",
        "def start_conversation():\n",
        "    initial_message = \"We are designing a new clone of Jira, we want to include AI in order to help with the creation of Tickets and assigning to the right person.\"\n",
        "\n",
        "    groupchat.messages.append({\n",
        "        \"sender\": user_proxy.name,\n",
        "        \"content\": initial_message,\n",
        "        \"role\": \"user\"\n",
        "    })\n",
        "\n",
        "    # Phase 1: Product Manager and Business Analyst Collaboration\n",
        "    phase_1_collaboration()\n",
        "\n",
        "    # Phase 2: Coder, Architect, and QA Collaboration\n",
        "    phase_2_collaboration()\n",
        "\n",
        "    # Phase 3: Final Revision and Improvement\n",
        "    phase_3_revision()\n",
        "\n",
        "    # Generate and deliver the final documentation\n",
        "    doc_agent.generate_final_document()\n",
        "\n",
        "# Start the group conversation\n",
        "start_conversation()\n"
      ],
      "metadata": {
        "id": "kQVzWbs--giW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6hK1R7O38Av-"
      }
    }
  ]
}